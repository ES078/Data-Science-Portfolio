{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ES078/Data-Science-Portfolio/blob/main/2024_SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI5VD13M8fY6"
      },
      "source": [
        "# Get Data and import libraries that we need"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwtYRl71geH"
      },
      "source": [
        "Version of this jupyter notebook: sentimentanalysis_V2.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdLsVQjs8R-X"
      },
      "outputs": [],
      "source": [
        "# Define where we will download the data\n",
        "path_data = \"/content/sample_data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni_sKSOI8uZJ"
      },
      "source": [
        "Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSPQApSIqEL9",
        "outputId": "83dda634-f759-4ac7-c3b5-e9e22bd136cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-03 15:27:26--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -P /content/sample_data/ -c \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1Ka_9Fk80iw"
      },
      "source": [
        "Decompress the archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyPwL6EYq-ej"
      },
      "outputs": [],
      "source": [
        "!tar -xf  /content/sample_data/aclImdb_v1.tar.gz -C /content/sample_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mksTVcHZ9MQ-"
      },
      "source": [
        "Check that the folder aclImdb exists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt0S2EZErSi0",
        "outputId": "9a79f514-b701-42dd-e2c5-c095eb64d6fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aclImdb\t\t   anscombe.json\t\tcalifornia_housing_train.csv  mnist_train_small.csv\n",
            "aclImdb_v1.tar.gz  california_housing_test.csv\tmnist_test.csv\t\t      README.md\n"
          ]
        }
      ],
      "source": [
        "!ls /content/sample_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZpg6f1u9W76"
      },
      "source": [
        "Import all required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bZ5Cng09LEl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "import nltk\n",
        "from gensim.models import Word2Vec, Phrases\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.utils import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wytbs1XU9zgG"
      },
      "source": [
        "Define function that reads all the files from a given folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEpWeGRq2QYd"
      },
      "outputs": [],
      "source": [
        "def read_data(path, files):\n",
        "    data = []\n",
        "    for f in files:\n",
        "        with open(path + f) as file:\n",
        "            ### BEGIN YOUR CODE HERE\n",
        "            line = file.readline()\n",
        "            data.append(line)\n",
        "            ### END YOUR CODE HERE\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zF9Dz-E-NQv"
      },
      "source": [
        "Load data (movie reviews), both for train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRmD7SSBrr71"
      },
      "outputs": [],
      "source": [
        "path_data_train_pos = path_data + '/aclImdb/train/pos/'\n",
        "path_data_train_neg = path_data + '/aclImdb/train/neg/'\n",
        "path_data_test_pos = path_data + '/aclImdb/test/pos/'\n",
        "path_data_test_neg = path_data + '/aclImdb/test/neg/'\n",
        "\n",
        "# Get the list of files from the four folders\n",
        "train_pos_files = os.listdir(path_data_train_pos)\n",
        "train_neg_files = os.listdir(path_data_train_neg)\n",
        "test_pos_files = os.listdir(path_data_test_pos)\n",
        "test_neg_files = os.listdir(path_data_test_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-OHWFG92TV_",
        "outputId": "71848ef7-3714-43ab-981b-182988566568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive reviews in training set: 12500\n",
            "Number of negative reviews in training set: 12500\n",
            "Number of positive reviews in testing set: 12500\n",
            "Number of negative reviews in testing set: 12500\n",
            "The dataset is balanced.\n",
            "\n",
            "Example of a positive review from training set:\n",
            "Bizarre horror movie filled with famous faces but stolen by Cristina Raines (later of TV's \"Flamingo Road\") as a pretty but somewhat unstable model with a gummy smile who is slated to pay for her attempted suicides by guarding the Gateway to Hell! The scenes with Raines modeling are very well captured, the mood music is perfect, Deborah Raffin is charming as Cristina's pal, but when Raines moves into a creepy Brooklyn Heights brownstone (inhabited by a blind priest on the top floor), things really start cooking. The neighbors, including a fantastically wicked Burgess Meredith and kinky couple Sylvia Miles & Beverly D'Angelo, are a diabolical lot, and Eli Wallach is great fun as a wily police detective. The movie is nearly a cross-pollination of \"Rosemary's Baby\" and \"The Exorcist\"--but what a combination! Based on the best-seller by Jeffrey Konvitz, \"The Sentinel\" is entertainingly spooky, full of shocks brought off well by director Michael Winner, who mounts a thoughtfully downbeat ending with skill. ***1/2 from ****\n",
            "\n",
            "Example of a negative review from training set:\n",
            "- Bad Stuff: This movie is real crap. Bad stunts for one thing, they looked so fake I thought this was \"The Twilight Zone\". The flashbacks are pretty much useless. One part of the movie he thinks taking his anger out on a window will make his life better. I wanna know the casting director and if he was high because the acting, even from the adults was horrid. A kissing scene in this movie even sucked. This movie killed the book. The book was great. I highly do not recommend this movie. Not even for educational purposes. <br /><br />- Good Stuff: I don't know what I can say really. There is some suspense parts that get you going, but they are quickly shot down by the bad stunt work and acting. <br /><br />- My Verdict: Do not watch.\n",
            "\n",
            "Example of a positive review from testing set:\n",
            "I rented this movie for two reasons. The first was all of the good things that I read about it. I definately was impressed, and couldn't agree more with all of the reviews I read. The second reason is because I know these guys. I don't know Mark as well as I do Mike. He hasn't changed much from the years we knew each other. I know him as \"the reaper\" from a local Milwaukee radio station (WMSE). The way he is in this film is genuinely Mike 100%. He once gave me a table that he made. It was a little one, about 15\" high, that said Metallica on it. The odd thing about it was it only had two legs. Sometimes it's the thought that counts, and Mike always has thought about others first.\n",
            "\n",
            "Example of a negative review from testing set:\n",
            "\"The Wizard of Menlo Park\" was deeply responsible for many things we take for granted in 2007: even if he did not invent them without rivals or assistants, he gave birth to the electric light, the phonograph, the motion picture camera, the electric car battery, the electric power grid (possibly his most important but least recalled invention), the pre-fabricated house, and innovations to the telephone and telegraph, as well as the ticker-tape machine and an early voting machine. The total number of patents is over 1,000 - far more than any other American Inventor.<br /><br />But Edison was a ruthless business competitor. He frequently had vast legal fights over the precedence of his inventions over rivals. The best example is the telephone, where he was one of seven or eight rivals with claims against Alexander Graham Bell. Actually Edison's invention here was not the central idea that Bell and Gray had come up with independently of each other in 1876, but an improvement on the sound quality of the phone receiver and transmitter that Bell did not develop. Still it was part of the huge 1888 Supreme Court decision that was the longest U.S. Supreme Court decision (a single volume of their reports!) written by Chief Justice Morrison Waite - which, by the way, killed the poor Chief Justice from overwork within weeks of completing it.<br /><br />In 1886 Edison found an equally ruthless competitor in the area of electric power grids for large cities. This was George Westinghouse, inventor of the railroad air break. Westinghouse's firm had gotten the assistance of a new inventor, and former Edison assistant, Nicola Tesla. Tesla developed \"alternating current\", which was a rival system to Edison's \"direct current\". Edison's system was basically a straight circuit system of electricity. Tesla's system allowed the current to be switched from one circuit to another - actually it was a better, and more efficient system. But Edison was determined to break this rival by a publicity campaign.<br /><br />It started with electric power lines. Edison early on had his lines put underground, so that they would not be endangered by weather conditions. But Westinghouse was forced to have his lines out in the open - like telephone lines. When there were several accidental deaths by repair linemen on Westinghouse's lines (in particular one incident where the repairman was burned alive in front of hundreds of horrified onlookers in Manhattan's business district), Edison started insisting that A.C. current was far more dangerous that D.C.<br /><br />One result of all this was Edison helping some subsidiary inventors with getting Westinghouse A.C. generators and dynamos for an electric chair. Edison himself always denied that he invented the electric chair, but he helped several lesser figures along the way - for the complete story read Mark Essig's EDISON & THE ELECTRIC CHAIR (New York: WALKER & COMPANY, 2003). <br /><br />Edison experiment himself with cats and dogs (experiments he was glad to show the public). In the long run, despite assisting in the invention of a new method of execution, Edison failed to dislodge the public support of Alternating Current. But he never stopped trying.<br /><br />In 1903 he had an opportunity to combine his campaign against Westinghouse and A.C. with his invention of the motion picture camera. He assisted in \"putting down\" a well known public elephant (\"Topsy\") who had killed several men. He did so by electrocuting the poor beast with A.C. But the entire killing is on film - and one can view it to this day. It is a pitiful looking film - whatever poor \"Topsy\" had done it was a poor beast - not a Machiavellian murderer. The moment we see the explosions of electricity sparks that show the death of the elephant, we are aware it will soon be over, but the sudden collapse of \"Topsy\" is still an unpleasant sight to view. The film leaves a bad flavor in the mouths of modern movie audiences. Yet, sad to say, it probably made a profit for Edison - his description of the film in his catalog of films shows real pride in his accomplishment here. In 1903 it may have been exciting entertainment for many Americans watching it. One is glad that more people are appalled by it today - sometimes one can sense the human race has improved a little bit.\n"
          ]
        }
      ],
      "source": [
        "### BEGIN YOUR CODE HERE\n",
        "\n",
        "# Read the data using the read_data() function\n",
        "train_data_pos = read_data(path_data_train_pos, train_pos_files)\n",
        "train_data_neg = read_data(path_data_train_neg, train_neg_files)\n",
        "test_data_pos = read_data(path_data_test_pos, test_pos_files)\n",
        "test_data_neg = read_data(path_data_test_neg, test_neg_files)\n",
        "\n",
        "# 1a. How many examples do we have in training for positive reviews? How many for negative reviews?\n",
        "num_train_pos = len(train_data_pos)\n",
        "num_train_neg = len(train_data_neg)\n",
        "\n",
        "print(f\"Number of positive reviews in training set: {num_train_pos}\")\n",
        "print(f\"Number of negative reviews in training set: {num_train_neg}\")\n",
        "\n",
        "# 1b. How many examples do we have in the testing set?\n",
        "num_test_pos = len(test_data_pos)\n",
        "num_test_neg = len(test_data_neg)\n",
        "\n",
        "print(f\"Number of positive reviews in testing set: {num_test_pos}\")\n",
        "print(f\"Number of negative reviews in testing set: {num_test_neg}\")\n",
        "\n",
        "# 1c. Is the dataset balanced or not?\n",
        "if num_train_pos == num_train_neg and num_test_pos == num_test_neg:\n",
        "    print(\"The dataset is balanced.\")\n",
        "else:\n",
        "    print(\"The dataset is not balanced.\")\n",
        "\n",
        "# 2. Print examples of positive and negative reviews from training and testing datasets\n",
        "print(\"\\nExample of a positive review from training set:\")\n",
        "print(train_data_pos[0] if train_data_pos else \"No data available\")\n",
        "\n",
        "print(\"\\nExample of a negative review from training set:\")\n",
        "print(train_data_neg[0] if train_data_neg else \"No data available\")\n",
        "\n",
        "print(\"\\nExample of a positive review from testing set:\")\n",
        "print(test_data_pos[0] if test_data_pos else \"No data available\")\n",
        "\n",
        "print(\"\\nExample of a negative review from testing set:\")\n",
        "print(test_data_neg[0] if test_data_neg else \"No data available\")\n",
        "\n",
        "### END YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONyrIyabhfx_",
        "outputId": "8845a450-c21b-4833-f352-a33a06de0cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 2000 samples for each category:\n",
            "Train positive reviews: 2000\n",
            "Train negative reviews: 2000\n",
            "Test positive reviews: 2000\n",
            "Test negative reviews: 2000\n"
          ]
        }
      ],
      "source": [
        "# Toggle between using a subset or the full dataset\n",
        "use_full_dataset = False # Set to False if you want to test with a smaller subset\n",
        "\n",
        "if use_full_dataset:\n",
        "    sample_number = len(train_data_pos)  # Use the full length of the dataset\n",
        "else:\n",
        "    sample_number = 2000 # Use a subset for faster testing\n",
        "\n",
        "# Use only the first `sample_number` reviews from each dataset\n",
        "train_data_pos = train_data_pos[:sample_number]\n",
        "train_data_neg = train_data_neg[:sample_number]\n",
        "test_data_pos = test_data_pos[:sample_number]\n",
        "test_data_neg = test_data_neg[:sample_number]\n",
        "\n",
        "# Print the number of samples being used for quick verification\n",
        "print(f\"Using {sample_number} samples for each category:\")\n",
        "print(f\"Train positive reviews: {len(train_data_pos)}\")\n",
        "print(f\"Train negative reviews: {len(train_data_neg)}\")\n",
        "print(f\"Test positive reviews: {len(test_data_pos)}\")\n",
        "print(f\"Test negative reviews: {len(test_data_neg)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDSNchHyBSiP"
      },
      "source": [
        "Create the data structures that we'll use for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iRunxcO214k",
        "outputId": "46561ec0-7515-40b1-de7d-5edb56d038f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the positive training examples is 2000\n",
            "Length of the negative training examples is 2000\n",
            "Length of the positive testing examples is 2000\n",
            "Length of the negative testing examples is 2000\n"
          ]
        }
      ],
      "source": [
        "### BEGIN YOUR CODE HERE\n",
        "# Assign the length of the train_data_pos to variable length_train_pos\n",
        "length_train_pos = len(train_data_pos)\n",
        "\n",
        "# Assign the length of the train_data_neg to variable length_train_neg\n",
        "length_train_neg = len(train_data_neg)\n",
        "\n",
        "# Assign the length of the test_data_pos to variable length_test_pos\n",
        "length_test_pos = len(test_data_pos)\n",
        "\n",
        "# Assign the length of the test_data_neg to variable length_test_neg\n",
        "length_test_neg = len(test_data_neg)\n",
        "### END YOUR CODE HERE\n",
        "\n",
        "# Print the lengths for verification\n",
        "print(\"Length of the positive training examples is\", length_train_pos)\n",
        "print(\"Length of the negative training examples is\", length_train_neg)\n",
        "print(\"Length of the positive testing examples is\", length_test_pos)\n",
        "print(\"Length of the negative testing examples is\", length_test_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP0iN7Y63DK8",
        "outputId": "2b65560a-4d82-4e7b-d224-72a757d502ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DataFrame shape: (4000, 2)\n",
            "Test DataFrame shape: (4000, 2)\n",
            "\n",
            "Training DataFrame sample:\n",
            "                                              review  label\n",
            "0  Bizarre horror movie filled with famous faces ...      1\n",
            "1  Well made and stylish while still ultimately m...      1\n",
            "2  Gojoe is part of a new wave of Japanese cinema...      1\n",
            "3  I watched this in July and even with the Chris...      1\n",
            "4  More a snapshot of the most popular pinup of a...      1\n",
            "\n",
            "Test DataFrame sample:\n",
            "                                              review  label\n",
            "0  I rented this movie for two reasons. The first...      1\n",
            "1  Watching this movie, I can't help drawing the ...      1\n",
            "2  A good entertainment but nothing more : in thi...      1\n",
            "3  There was nothing else on tv yesterday afterno...      1\n",
            "4  You will be able to tell within the first 30 s...      1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create the training DataFrame with examples and labels\n",
        "# Concatenate positive and negative training examples, then pair each example with a label: 1 for positive, 0 for negative\n",
        "data_train = pd.DataFrame(\n",
        "    zip(train_data_pos + train_data_neg, [1] * length_train_pos + [0] * length_train_neg),\n",
        "    columns=['review', 'label']\n",
        ")\n",
        "\n",
        "# Create the test DataFrame with examples and labels\n",
        "# Concatenate positive and negative test examples, then pair each example with a label: 1 for positive, 0 for negative\n",
        "data_test = pd.DataFrame(\n",
        "    zip(test_data_pos + test_data_neg, [1] * length_test_pos + [0] * length_test_neg),\n",
        "    columns=['review', 'label']\n",
        ")\n",
        "\n",
        "# Combine all reviews into a single list (training + test, positive + negative)\n",
        "all_reviews = train_data_pos + train_data_neg + test_data_pos + test_data_neg\n",
        "\n",
        "# Print the shapes of the dataframes to confirm sizes\n",
        "print(f\"Training DataFrame shape: {data_train.shape}\")\n",
        "print(f\"Test DataFrame shape: {data_test.shape}\")\n",
        "\n",
        "# Display the first few rows of the training and test DataFrames for verification\n",
        "print(\"\\nTraining DataFrame sample:\")\n",
        "print(data_train.head())\n",
        "\n",
        "print(\"\\nTest DataFrame sample:\")\n",
        "print(data_test.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AgnWZ6xmPKC",
        "outputId": "06d50e5d-cab2-4134-c586-857c5603295b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the train reviews is 4000\n",
            "The length of the test reviews is 4000\n",
            "The length of all reviews is 8000\n"
          ]
        }
      ],
      "source": [
        "print(\"The length of the train reviews is\",len(data_train))\n",
        "print(\"The length of the test reviews is\",len(data_test))\n",
        "print(\"The length of all reviews is\",len(all_reviews))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGx0YdcMDKmk"
      },
      "source": [
        "## The following are functions for preprocessing text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kUEiSjwDWtq",
        "outputId": "98e24db7-cb1d-468e-8fa7-bd81cd984389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Download stopwords and wordnet vectors\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "counter = 0\n",
        "REPLACE_WITH_SPACE = re.compile(r'[^A-Za-z\\s]')\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "# Declare the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upAJm0cL4m55"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "REPLACE_WITH_SPACE = re.compile(r\"[^a-zA-Z]\")\n",
        "\n",
        "# Global counter for tracking progress (used in the preprocess function)\n",
        "counter = 0\n",
        "\n",
        "# Function 1: Clean Review\n",
        "def clean_review(raw_review: str) -> str:\n",
        "\n",
        "    # 1. Remove HTML tags using BeautifulSoup\n",
        "    review_text = BeautifulSoup(str(raw_review), \"lxml\").get_text()\n",
        "\n",
        "    # 2. Remove non-letter characters (anything that's not A-Z or a-z)\n",
        "    letters_only = REPLACE_WITH_SPACE.sub(\" \", review_text)\n",
        "\n",
        "    # 3. Convert to lowercase\n",
        "    lowercase_letters = letters_only.lower()\n",
        "\n",
        "    return lowercase_letters\n",
        "\n",
        "# Function 2: Lemmatize and Remove Stopwords\n",
        "def lemmatize(tokens: list) -> list:\n",
        "\n",
        "    # 1. Lemmatize words as nouns\n",
        "    tokens = list(map(lemmatizer.lemmatize, tokens))\n",
        "\n",
        "    # 2. Further lemmatize words as verbs\n",
        "    lemmatized_tokens = list(map(lambda x: lemmatizer.lemmatize(x, \"v\"), tokens))\n",
        "\n",
        "    # 3. Remove stopwords\n",
        "    meaningful_words = list(filter(lambda x: x not in stop_words, lemmatized_tokens))\n",
        "\n",
        "    return meaningful_words\n",
        "\n",
        "\n",
        "# Function 3: Full Preprocessing Pipeline\n",
        "def preprocess(review: str, total: int, show_progress: bool = True) -> list:\n",
        "\n",
        "    global counter\n",
        "\n",
        "    # Display progress\n",
        "    if show_progress:\n",
        "        counter += 1\n",
        "        print('Processing... %6i/%6i' % (counter, total), end='\\r')\n",
        "\n",
        "    # 1. Clean the text\n",
        "    cleaned_review = clean_review(review)\n",
        "\n",
        "    # 2. Tokenize the cleaned review into individual words\n",
        "    tokens = word_tokenize(cleaned_review)\n",
        "\n",
        "    # 3. Lemmatize tokens and remove stopwords\n",
        "    lemmas = lemmatize(tokens)\n",
        "\n",
        "    # 4. Return the processed tokens (list of meaningful words)\n",
        "    return lemmas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZheAzAmxEIRi"
      },
      "source": [
        "## Preprocess the text of the reviews by removing the non-word characters, converting everything to lower case, and lemmatizing words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qCpWwk299fJ",
        "outputId": "c8e403fa-d9cf-49b6-a761-b7f9812ac522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Raw Review Text ###\n",
            "Bizarre horror movie filled with famous faces but stolen by Cristina Raines (later of TV's \"Flamingo Road\") as a pretty but somewhat unstable model with a gummy smile who is slated to pay for her attempted suicides by guarding the Gateway to Hell! The scenes with Raines modeling are very well captured, the mood music is perfect, Deborah Raffin is charming as Cristina's pal, but when Raines moves into a creepy Brooklyn Heights brownstone (inhabited by a blind priest on the top floor), things really start cooking. The neighbors, including a fantastically wicked Burgess Meredith and kinky couple Sylvia Miles & Beverly D'Angelo, are a diabolical lot, and Eli Wallach is great fun as a wily police detective. The movie is nearly a cross-pollination of \"Rosemary's Baby\" and \"The Exorcist\"--but what a combination! Based on the best-seller by Jeffrey Konvitz, \"The Sentinel\" is entertainingly spooky, full of shocks brought off well by director Michael Winner, who mounts a thoughtfully downbeat ending with skill. ***1/2 from ****\n",
            "\n",
            "### Review Label ###\n",
            "Label: 1 (1 for positive, 0 for negative)\n",
            "\n",
            "### Preprocessed Review Text ###\n",
            "Processing...      1/     1\r['bizarre', 'horror', 'movie', 'fill', 'famous', 'face', 'steal', 'cristina', 'rain', 'later', 'tv', 'flamingo', 'road', 'pretty', 'somewhat', 'unstable', 'model', 'gummy', 'smile', 'slat', 'pay', 'attempt', 'suicide', 'guard', 'gateway', 'hell', 'scene', 'rain', 'model', 'well', 'capture', 'mood', 'music', 'perfect', 'deborah', 'raffin', 'charm', 'cristina', 'pal', 'rain', 'move', 'creepy', 'brooklyn', 'height', 'brownstone', 'inhabit', 'blind', 'priest', 'top', 'floor', 'thing', 'really', 'start', 'cook', 'neighbor', 'include', 'fantastically', 'wicked', 'burgess', 'meredith', 'kinky', 'couple', 'sylvia', 'mile', 'beverly', 'angelo', 'diabolical', 'lot', 'eli', 'wallach', 'great', 'fun', 'wily', 'police', 'detective', 'movie', 'nearly', 'cross', 'pollination', 'rosemary', 'baby', 'exorcist', 'combination', 'base', 'best', 'seller', 'jeffrey', 'konvitz', 'sentinel', 'entertainingly', 'spooky', 'full', 'shock', 'bring', 'well', 'director', 'michael', 'winner', 'mount', 'thoughtfully', 'downbeat', 'end', 'skill']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# Download all NLTK data\n",
        "nltk.download('all')\n",
        "\n",
        "# Step 1: Display the first review text from the training data\n",
        "print(\"### Raw Review Text ###\")\n",
        "first_review_text = data_train['review'][0]\n",
        "print(first_review_text)\n",
        "\n",
        "# Step 2: Display the label associated with the first review\n",
        "print(\"\\n### Review Label ###\")\n",
        "first_review_label = data_train['label'][0]\n",
        "print(f\"Label: {first_review_label} (1 for positive, 0 for negative)\")\n",
        "\n",
        "# Step 3: Display the preprocessed text of the first review\n",
        "print(\"\\n### Preprocessed Review Text ###\")\n",
        "preprocessed_review = preprocess(first_review_text, total=1)\n",
        "print(preprocessed_review)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8v52gEBEtUi"
      },
      "source": [
        "Let's preproces the entire set of reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhjaSx_R_QUL",
        "outputId": "4ccdb97f-6d6e-4f81-d3b2-453179412192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Preprocessing all reviews ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-cbe43f4c6ab2>:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  review_text = BeautifulSoup(str(raw_review), \"lxml\").get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing...   8000/  8000\n",
            "### Sample Preprocessed Reviews ###\n",
            "Review 1: ['bizarre', 'horror', 'movie', 'fill', 'famous', 'face', 'steal', 'cristina', 'rain', 'later', 'tv', 'flamingo', 'road', 'pretty', 'somewhat', 'unstable', 'model', 'gummy', 'smile', 'slat', 'pay', 'attempt', 'suicide', 'guard', 'gateway', 'hell', 'scene', 'rain', 'model', 'well', 'capture', 'mood', 'music', 'perfect', 'deborah', 'raffin', 'charm', 'cristina', 'pal', 'rain', 'move', 'creepy', 'brooklyn', 'height', 'brownstone', 'inhabit', 'blind', 'priest', 'top', 'floor', 'thing', 'really', 'start', 'cook', 'neighbor', 'include', 'fantastically', 'wicked', 'burgess', 'meredith', 'kinky', 'couple', 'sylvia', 'mile', 'beverly', 'angelo', 'diabolical', 'lot', 'eli', 'wallach', 'great', 'fun', 'wily', 'police', 'detective', 'movie', 'nearly', 'cross', 'pollination', 'rosemary', 'baby', 'exorcist', 'combination', 'base', 'best', 'seller', 'jeffrey', 'konvitz', 'sentinel', 'entertainingly', 'spooky', 'full', 'shock', 'bring', 'well', 'director', 'michael', 'winner', 'mount', 'thoughtfully', 'downbeat', 'end', 'skill']\n",
            "Review 2: ['well', 'make', 'stylish', 'still', 'ultimately', 'make', 'sense', 'thriller', 'would', 'work', 'better', 'non', 'giallo', 'fan', 'get', 'interest', 'genre', 'later', 'argento', 'entry', 'go', 'overboard', 'direction', 'fan', 'craze', 'italian', 'thriller', 'appreciate', 'george', 'hilton', 'turn', 'character', 'take', 'put', 'camera', 'work', 'fresh', 'dash', 'graphic', 'violence', 'odd', 'appropriate', 'choice', 'good', 'overblown', 'music', 'score', 'well', 'less', 'know', 'story', 'better', 'make', 'work', 'thing', 'lack', 'keep', 'great', 'sergio', 'martino', 'direct', 'giallo', 'story', 'extra', 'sexual', 'psychological', 'element', 'put', 'top', 'routine', 'mystery', 'character', 'well', 'define', 'live', 'die', 'accord', 'plot', 'accord', 'virtue', 'flaw', 'recent', 'dvd', 'release', 'beautiful', 'look', 'definitely', 'way', 'see', 'film', 'unless', 'ever', 'get', 'art', 'house', 'screen', 'seem', 'unlikely']\n",
            "Review 3: ['gojoe', 'part', 'new', 'wave', 'japanese', 'cinema', 'take', 'creative', 'director', 'editor', 'photographer', 'work', 'historic', 'theme', 'japanese', 'call', 'period', 'piece', 'gojoe', 'extremely', 'creative', 'term', 'color', 'photography', 'edit', 'brilliant', 'even', 'new', 'wave', 'japanese', 'samurai', 'film', 'allow', 'peek', 'traditional', 'belief', 'shamanism', 'demon', 'occult', 'power', 'certainly', 'part', 'ancient', 'culture', 'really', 'explore', 'kurosawa', 'samurai', 'epic', 'zaitochi', 'series', 'another', 'fine', 'example', 'genre', 'onmyoji', 'would', 'place', 'director', 'sogo', 'ichii', 'one', 'interest', 'creative', 'new', 'wave', 'japanese', 'director', 'recent', 'japanese', 'period', 'piece', 'would', 'highly', 'recommend', 'include', 'yomada', 'twilight', 'samurai', 'shintaro', 'katsu', 'zatoichi', 'blind', 'swordsman']\n"
          ]
        }
      ],
      "source": [
        "# Preprocessing each review in the all_reviews list.\n",
        "print(\"### Preprocessing all reviews ###\")\n",
        "counter = 0\n",
        "all_reviews_preprocessed = [preprocess(x, total=len(all_reviews)) for x in all_reviews]\n",
        "\n",
        "# Display sample of the preprocessed reviews\n",
        "print(\"\\n### Sample Preprocessed Reviews ###\")\n",
        "for i in range(3):\n",
        "    print(f\"Review {i + 1}: {all_reviews_preprocessed[i]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o9C3aCI8TiF",
        "outputId": "382e903f-be83-4f68-d06f-87e238616b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples (preprocessed): 4000\n",
            "Number of testing examples (preprocessed): 4000\n",
            "\n",
            "### Sample Preprocessed Training Review ###\n",
            "[['bizarre', 'horror', 'movie', 'fill', 'famous', 'face', 'steal', 'cristina', 'rain', 'later', 'tv', 'flamingo', 'road', 'pretty', 'somewhat', 'unstable', 'model', 'gummy', 'smile', 'slat', 'pay', 'attempt', 'suicide', 'guard', 'gateway', 'hell', 'scene', 'rain', 'model', 'well', 'capture', 'mood', 'music', 'perfect', 'deborah', 'raffin', 'charm', 'cristina', 'pal', 'rain', 'move', 'creepy', 'brooklyn', 'height', 'brownstone', 'inhabit', 'blind', 'priest', 'top', 'floor', 'thing', 'really', 'start', 'cook', 'neighbor', 'include', 'fantastically', 'wicked', 'burgess', 'meredith', 'kinky', 'couple', 'sylvia', 'mile', 'beverly', 'angelo', 'diabolical', 'lot', 'eli', 'wallach', 'great', 'fun', 'wily', 'police', 'detective', 'movie', 'nearly', 'cross', 'pollination', 'rosemary', 'baby', 'exorcist', 'combination', 'base', 'best', 'seller', 'jeffrey', 'konvitz', 'sentinel', 'entertainingly', 'spooky', 'full', 'shock', 'bring', 'well', 'director', 'michael', 'winner', 'mount', 'thoughtfully', 'downbeat', 'end', 'skill'], ['well', 'make', 'stylish', 'still', 'ultimately', 'make', 'sense', 'thriller', 'would', 'work', 'better', 'non', 'giallo', 'fan', 'get', 'interest', 'genre', 'later', 'argento', 'entry', 'go', 'overboard', 'direction', 'fan', 'craze', 'italian', 'thriller', 'appreciate', 'george', 'hilton', 'turn', 'character', 'take', 'put', 'camera', 'work', 'fresh', 'dash', 'graphic', 'violence', 'odd', 'appropriate', 'choice', 'good', 'overblown', 'music', 'score', 'well', 'less', 'know', 'story', 'better', 'make', 'work', 'thing', 'lack', 'keep', 'great', 'sergio', 'martino', 'direct', 'giallo', 'story', 'extra', 'sexual', 'psychological', 'element', 'put', 'top', 'routine', 'mystery', 'character', 'well', 'define', 'live', 'die', 'accord', 'plot', 'accord', 'virtue', 'flaw', 'recent', 'dvd', 'release', 'beautiful', 'look', 'definitely', 'way', 'see', 'film', 'unless', 'ever', 'get', 'art', 'house', 'screen', 'seem', 'unlikely']]\n",
            "\n",
            "### Sample Preprocessed Testing Review ###\n",
            "[['rent', 'movie', 'two', 'reason', 'first', 'wa', 'good', 'thing', 'read', 'definately', 'wa', 'impress', 'agree', 'review', 'read', 'second', 'reason', 'know', 'guy', 'know', 'mark', 'well', 'mike', 'change', 'much', 'year', 'know', 'know', 'reaper', 'local', 'milwaukee', 'radio', 'station', 'wmse', 'way', 'film', 'genuinely', 'mike', 'give', 'table', 'make', 'wa', 'little', 'one', 'high', 'say', 'metallica', 'odd', 'thing', 'wa', 'two', 'leg', 'sometimes', 'think', 'count', 'mike', 'always', 'ha', 'think', 'others', 'first'], ['watch', 'movie', 'help', 'draw', 'comparison', 'wild', 'reed', 'another', 'thoughtful', 'film', 'teenager', 'come', 'age', 'like', 'wild', 'reed', 'movie', 'slow', 'director', 'would', 'hurry', 'want', 'quick', 'resolution', 'thing', 'watch', 'movie', 'like', 'slice', 'life', 'begin', 'imperfectly', 'end', 'imperfectly', 'resolution', 'anything', 'happily', 'ever', 'anybody', 'like', 'real', 'life', 'movie', 'real', 'get', 'act', 'surprisingly', 'good', 'director', 'fond', 'long', 'really', 'long', 'shoot', 'actor', 'actress', 'excel', 'show', 'subtlety', 'inner', 'think', 'love', 'movie', 'almost', 'watch', 'glad', 'movie', 'everyone', 'let', 'grow', 'reward']]\n"
          ]
        }
      ],
      "source": [
        "num_train = len(train_data_pos) + len(train_data_neg)\n",
        "\n",
        "# Slice preprocessed reviews to get only the training set portion\n",
        "X_train_preprocessed = all_reviews_preprocessed[:num_train]\n",
        "\n",
        "# Slice preprocessed reviews to get only the testing set portion\n",
        "X_test_preprocessed = all_reviews_preprocessed[num_train:]\n",
        "\n",
        "# Print the length of each training example to verify\n",
        "print(f\"Number of training examples (preprocessed): {len(X_train_preprocessed)}\")\n",
        "print(f\"Number of testing examples (preprocessed): {len(X_test_preprocessed)}\")\n",
        "\n",
        "print(\"\\n### Sample Preprocessed Training Review ###\")\n",
        "print(X_train_preprocessed[:2])\n",
        "\n",
        "print(\"\\n### Sample Preprocessed Testing Review ###\")\n",
        "print(X_test_preprocessed[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnCqRe7VN8Xg",
        "outputId": "4ab16a66-641a-43b5-9deb-d5bebb13482c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "len(train_data_pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8aKuguU8TiI",
        "outputId": "1d38a9da-4300-44ee-9d43-51842a7255b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n"
          ]
        }
      ],
      "source": [
        "# Let's see how many reviews we have in total for training\n",
        "# We should get 2000 if you kept the sample_number=1000\n",
        "# print(X_train_preprocessed.shape)\n",
        "print(len(X_train_preprocessed))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifjZTpu2FKwk"
      },
      "source": [
        "## Compute Word2Vec vectors on all reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl1V-yyBFGti",
        "outputId": "4ae43864-b87c-4009-f810-fe1cd50bf5ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Compute Phrases Begin ###\n",
            "### Compute Phrases End ###\n",
            "\n",
            "### Sample Review with Bigrams ###\n",
            "['bizarre', 'horror', 'movie', 'fill', 'famous', 'face', 'steal', 'cristina_rain', 'later', 'tv', 'flamingo', 'road', 'pretty', 'somewhat', 'unstable', 'model', 'gummy', 'smile', 'slat', 'pay', 'attempt', 'suicide', 'guard', 'gateway', 'hell', 'scene', 'rain', 'model', 'well', 'capture', 'mood', 'music', 'perfect', 'deborah', 'raffin', 'charm', 'cristina', 'pal', 'rain', 'move', 'creepy', 'brooklyn', 'height', 'brownstone', 'inhabit', 'blind', 'priest', 'top', 'floor', 'thing', 'really', 'start', 'cook', 'neighbor', 'include', 'fantastically', 'wicked', 'burgess_meredith', 'kinky', 'couple', 'sylvia', 'mile', 'beverly_angelo', 'diabolical', 'lot', 'eli_wallach', 'great', 'fun', 'wily', 'police_detective', 'movie', 'nearly', 'cross', 'pollination', 'rosemary_baby', 'exorcist', 'combination', 'base', 'best_seller', 'jeffrey', 'konvitz', 'sentinel', 'entertainingly', 'spooky', 'full', 'shock', 'bring', 'well', 'director', 'michael', 'winner', 'mount', 'thoughtfully', 'downbeat', 'end', 'skill']\n",
            "\n",
            "### Sample Review with Trigrams ###\n",
            "['bizarre', 'horror_movie', 'fill', 'famous', 'face', 'steal', 'cristina_rain', 'later', 'tv', 'flamingo', 'road', 'pretty', 'somewhat', 'unstable', 'model', 'gummy', 'smile', 'slat', 'pay', 'attempt', 'suicide', 'guard', 'gateway', 'hell', 'scene', 'rain', 'model', 'well', 'capture', 'mood', 'music', 'perfect', 'deborah', 'raffin', 'charm', 'cristina', 'pal', 'rain', 'move', 'creepy', 'brooklyn', 'height', 'brownstone', 'inhabit', 'blind', 'priest', 'top', 'floor', 'thing', 'really', 'start', 'cook', 'neighbor', 'include', 'fantastically', 'wicked', 'burgess_meredith', 'kinky', 'couple', 'sylvia_mile', 'beverly_angelo', 'diabolical', 'lot', 'eli_wallach', 'great_fun', 'wily', 'police_detective', 'movie', 'nearly', 'cross', 'pollination', 'rosemary_baby', 'exorcist', 'combination', 'base', 'best_seller', 'jeffrey', 'konvitz', 'sentinel', 'entertainingly', 'spooky', 'full', 'shock', 'bring', 'well', 'director_michael', 'winner', 'mount', 'thoughtfully', 'downbeat_end', 'skill']\n"
          ]
        }
      ],
      "source": [
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "print(\"### Compute Phrases Begin ###\")\n",
        "\n",
        "# Compute bigrams from all preprocessed reviews\n",
        "bigrams_model = Phrases(sentences=all_reviews_preprocessed, min_count=5, threshold=10)\n",
        "bigrams = Phraser(bigrams_model)\n",
        "\n",
        "# Transform all reviews to include detected bigrams\n",
        "all_reviews_bigrams = [bigrams[review] for review in all_reviews_preprocessed]\n",
        "\n",
        "# Compute trigrams based on the bigrams output\n",
        "trigrams_model = Phrases(sentences=all_reviews_bigrams, min_count=3, threshold=5)\n",
        "trigrams = Phraser(trigrams_model)\n",
        "\n",
        "# Transform all reviews to include detected trigrams\n",
        "all_reviews_trigrams = [trigrams[review] for review in all_reviews_bigrams]\n",
        "\n",
        "print(\"### Compute Phrases End ###\")\n",
        "\n",
        "print(\"\\n### Sample Review with Bigrams ###\")\n",
        "print(all_reviews_bigrams[0])\n",
        "\n",
        "print(\"\\n### Sample Review with Trigrams ###\")\n",
        "print(all_reviews_trigrams[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRepsD6YCnCK",
        "outputId": "2060b0c1-4bf3-41c6-8ae0-b7d7b828baa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['space_station', 'near', 'the', 'solar', 'system']\n"
          ]
        }
      ],
      "source": [
        "# Test how our phrase looks after calling the bigrams\n",
        "print(bigrams['space station near the solar system'.split()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1x4MR6Iv1UW",
        "outputId": "444341eb-4a9e-4fa9-dbf1-ac924f774e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['space_station', 'near', 'the', 'solar', 'system']\n"
          ]
        }
      ],
      "source": [
        "# Test how our phrase looks after calling the trigrams\n",
        "# Do you notice any difference compared with the bigrams?\n",
        "print(trigrams[bigrams['space station near the solar system'.split()]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no71z1UvDFBn",
        "outputId": "184eac0e-ddb8-4d4a-e276-1b4687f8cff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start learning the word embedding\n",
            "Done learning\n"
          ]
        }
      ],
      "source": [
        "print(\"Start learning the word embedding\")\n",
        "embedding_vector_size = 256\n",
        "trigram_model = Word2Vec(\n",
        "    sentences=all_reviews_trigrams,\n",
        "    vector_size=256,\n",
        "    min_count=5,\n",
        "    window=5,\n",
        "    workers=4,\n",
        "    sg=1,\n",
        "    epochs=10\n",
        ")\n",
        "print(\"Done learning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AcRcTpIJhXv"
      },
      "source": [
        "Check what is the vocabulary size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SKWyBnZD7Ig",
        "outputId": "0967f98b-7281-483c-8864-8c24ac23d737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 17976\n"
          ]
        }
      ],
      "source": [
        "print(\"Vocabulary size:\", len(trigram_model.wv))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2eqqZpSJ5eH"
      },
      "source": [
        "Let's check the most similar words for \"movie\" & \"galaxy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEQ3aXWZEBDn",
        "outputId": "5c2ba6df-8564-48a5-abe9-32bc73c92869"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sci_fi_movie', 0.6957032680511475),\n",
              " ('dark_harvest', 0.6926688551902771),\n",
              " ('foreign_film', 0.6889390349388123),\n",
              " ('definately', 0.6885450482368469),\n",
              " ('movie_sci_fi', 0.6861522793769836),\n",
              " ('roll_floor', 0.6855193972587585),\n",
              " ('cant_believe', 0.6846780180931091),\n",
              " ('wait_wait', 0.6812870502471924),\n",
              " ('pola_x', 0.6799310445785522),\n",
              " ('commenter', 0.6776955723762512)]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "trigram_model.wv.most_similar('movie')\n",
        "# If you are working with the subset of 1000 reviews, the most similar words might not be\n",
        "# the most relevant ones. You can remove the constraint of working with only 1000 reviews,\n",
        "# and compare what are the most similar words again, but please be aware that this might\n",
        "# increase the training time of the word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH2o-1CXtGgk",
        "outputId": "2c06b3fe-e303-48de-c805-0ffc2eed0596"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('car_chase', 0.5393440127372742),\n",
              " ('van_damme', 0.5344326496124268),\n",
              " ('martial_art', 0.5282161831855774),\n",
              " ('action_sequence', 0.5177546739578247),\n",
              " ('fast_pace', 0.5166077017784119),\n",
              " ('shoot_em', 0.5149741768836975),\n",
              " ('low_grade', 0.5104499459266663),\n",
              " ('enrich', 0.5050894618034363),\n",
              " ('weak_attempt', 0.5010796785354614),\n",
              " ('jean_claude', 0.49659088253974915)]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "trigram_model.wv.most_similar('action')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulf_As1CKO88"
      },
      "source": [
        "Given a list of words identify which word does not match with the others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9-7HRVEniDaO",
        "outputId": "9218f495-94e8-49ab-d495-886dc2e77c95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'planet'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "trigram_model.wv.doesnt_match(['movie', 'action', 'planet'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRxTbMIXKaza"
      },
      "source": [
        "## **Transform our reviews from the training set into vectors\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epORdcayEJDx",
        "outputId": "a7533169-325b-4d8e-fc9b-84fc92008fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert sentences to sentences with ngrams... (done)\n",
            "Vectorizing sentences... (done)\n",
            "Transform sentences to sequences on the train set... (done)\n",
            "Vectorizing sentences... (done)\n",
            "Transform sentences to sequences on the test set... (done)\n"
          ]
        }
      ],
      "source": [
        "def vectorize_data(data, vocab: dict) -> list:\n",
        "    \"\"\"Converts tokenized data into vectors based on the vocabulary.\"\"\"\n",
        "    print('Vectorizing sentences...', end='\\r')\n",
        "    keys = list(vocab.keys())\n",
        "    filter_unknown = lambda word: vocab.get(word, None) is not None\n",
        "    encode = lambda review: list(map(keys.index, filter(filter_unknown, review)))\n",
        "    vectorized = list(map(encode, data))\n",
        "    print('Vectorizing sentences... (done)')\n",
        "    return vectorized\n",
        "\n",
        "print('Convert sentences to sentences with ngrams...', end='\\r')\n",
        "X_data = trigrams[bigrams[X_train_preprocessed]]\n",
        "print('Convert sentences to sentences with ngrams... (done)')\n",
        "\n",
        "input_length = 150\n",
        "\n",
        "X_pad_train = pad_sequences(\n",
        "    sequences=vectorize_data(X_data, vocab=trigram_model.wv.key_to_index),\n",
        "    maxlen=input_length,\n",
        "    padding='post'\n",
        ")\n",
        "print('Transform sentences to sequences on the train set... (done)')\n",
        "\n",
        "X_data_test = trigrams[bigrams[X_test_preprocessed]]\n",
        "X_pad_test = pad_sequences(\n",
        "    sequences=vectorize_data(X_data_test, vocab=trigram_model.wv.key_to_index),\n",
        "    maxlen=input_length,\n",
        "    padding='post'\n",
        ")\n",
        "print('Transform sentences to sequences on the test set... (done)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy4ZO3TrhXO8",
        "outputId": "94ae3106-41b8-4e44-c3ae-85bf44d8b20a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13717,    57,  7946,    38,  1184,  9057,  3053,    44,  7167,\n",
              "         373,   794,   101,  4668, 13717,   541,  1184,   867,   747,\n",
              "       16159,   315,    15,  7946,   794,  3038,     2,   522,  6594,\n",
              "        1689,  1091,   987,  4722,   384,   223,    57,  1778,   966,\n",
              "          19,  1273,  5732,  3038,  1152,   130,    65,   430,   317,\n",
              "         297,    18,   155,    55,     3,    59,  1184,  7946,   794,\n",
              "          55,   954,   794,  4668,    18,  1017,   179, 12242,  3038,\n",
              "       13657,  1570, 13656,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# For a given example, each number in the vector represents the position of the word in the vocabulary\n",
        "X_pad_train[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AN9nzI8L_ET"
      },
      "source": [
        "# Train a classifier based on a particular type of recurrent neural network called LSTM to differentiate between positive and negative reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzUtHSypGPLq",
        "outputId": "9590a871-09e2-4664-d2e8-91fbc9a48466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 3200\n",
            "Validation set size: 800\n",
            "Test set size: 4000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Split training data into train and validation sets (80% train, 20% validation data split)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_pad_train,  # Padded training data\n",
        "    data_train['label'],  # Labels\n",
        "    test_size=0.2,  # 20% validation split\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Step 2: Assign test data\n",
        "X_test = X_pad_test\n",
        "y_test = data_test['label']\n",
        "\n",
        "# Print dataset sizez for verification\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Validation set size: {X_val.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "_E7PFRSS30ar",
        "outputId": "2ee803be-c76e-412f-d5c0-3f9e013f1f15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "3995    0\n",
              "3996    0\n",
              "3997    0\n",
              "3998    0\n",
              "3999    0\n",
              "Name: label, Length: 4000, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "data_test['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbChe-TENItQ"
      },
      "source": [
        "Define the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q7SQhK9F3Zp",
        "outputId": "0e330532-c389-4a15-ab51-4a8b8c1b4fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "### Begin your code here\n",
        "# Define a neural network model\n",
        "# TIP: Use the same sequential model in order to define the network:\n",
        "# https://www.tensorflow.org/guide/keras/sequential_model\n",
        "# You can also see an example in the MNIST lab.\n",
        "# Add the following layers:\n",
        "# 1. an Embedding layer of the following form:\n",
        "# tf.keras.layers.Embedding(\n",
        "#         input_dim = trigram_model.wv.vectors.shape[0],\n",
        "#         output_dim = trigram_model.wv.vectors.shape[1],\n",
        "#         input_length = input_length,\n",
        "#         weights = [trigram_model.wv.vectors],\n",
        "#         trainable=False)\n",
        "# 2. A Bidirectional layer with LSTM, with 128 internal units and a recurrent dropout of 0.1\n",
        "# A sentence can be considered a temporal sequence, where the order of the words\n",
        "# might be important. This is why we need a temporal model, like a Long short-term memory model.\n",
        "# A bidirectional model, simply means that the we want to parse the data both forward\n",
        "# and backwards. This allows the network to capture both past and future context for each time step.\n",
        "# See example here: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional\n",
        "# eg: tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, recurrent_dropout=0.1)),\n",
        "# 3. A dropout layer with 0.25 probability\n",
        "# You will find an example of dropout layer in the previous MNIST lab.\n",
        "# See example here: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\n",
        "# 4. A Dense layer with 64 internal units\n",
        "# You will find an example of a dense layer in the previous MNIST lab.\n",
        "# 5. A dropout layer with 0.3 probability\n",
        "# 6. A final dense layer with 1 neuron and a sigmoid activation function\n",
        "# tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense, GRU\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "vocab_size = len(trigram_model.wv.key_to_index)\n",
        "embedding_dim = trigram_model.wv.vectors.shape[1]\n",
        "\n",
        "# LSTM model\n",
        "model1 = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[trigram_model.wv.vectors], trainable=True),\n",
        "    BatchNormalization(),\n",
        "    Bidirectional(LSTM(256, return_sequences=True, recurrent_dropout=0.2)),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(128)),\n",
        "    Dropout(0.15),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.1),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Stacked LSTM\n",
        "model2 = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=128, input_length=input_length),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    Dropout(0.15),\n",
        "    LSTM(64),\n",
        "    Dropout(0.15),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.1),\n",
        "    Dense(1, activation='sigmoid')\n",
        "\n",
        "])\n",
        "\n",
        "# GRU with bidirectional layer\n",
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "### End your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UyMUAxPmp5Z"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Model 1 - Basic LSTM\n",
        "model1.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.0005),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Model 2 - Stacked LSTM\n",
        "model2.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.0007),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Model 3 - Bidirectional GRU\n",
        "model3.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.0003),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91DuUpuBHJUn",
        "outputId": "700dcb11-2363-4a16-8ec6-2f045faf78a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 363ms/step - accuracy: 0.6512 - loss: 0.5910 - val_accuracy: 0.6800 - val_loss: 0.6952\n",
            "Epoch 2/4\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 351ms/step - accuracy: 0.8557 - loss: 0.3431 - val_accuracy: 0.7350 - val_loss: 0.9386\n",
            "Epoch 3/4\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 346ms/step - accuracy: 0.9336 - loss: 0.1861 - val_accuracy: 0.8238 - val_loss: 0.5999\n",
            "Epoch 4/4\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 361ms/step - accuracy: 0.9756 - loss: 0.0687 - val_accuracy: 0.8163 - val_loss: 0.6369\n",
            "Epoch 1/8\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.5370 - loss: 0.6910 - val_accuracy: 0.4863 - val_loss: 0.6937\n",
            "Epoch 2/8\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5249 - loss: 0.6921 - val_accuracy: 0.5075 - val_loss: 0.6932\n",
            "Epoch 3/8\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6147 - loss: 0.6624 - val_accuracy: 0.5325 - val_loss: 0.6983\n",
            "Epoch 4/8\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6238 - loss: 0.5800 - val_accuracy: 0.5038 - val_loss: 0.7663\n",
            "Epoch 5/8\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6742 - loss: 0.5229 - val_accuracy: 0.7013 - val_loss: 0.6747\n",
            "Epoch 6/8\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8079 - loss: 0.4465 - val_accuracy: 0.6888 - val_loss: 0.7862\n",
            "Epoch 7/8\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8065 - loss: 0.4391 - val_accuracy: 0.6988 - val_loss: 0.7243\n",
            "Epoch 8/8\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8431 - loss: 0.3946 - val_accuracy: 0.6675 - val_loss: 0.8191\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.4999 - loss: 0.6928 - val_accuracy: 0.5675 - val_loss: 0.6749\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8081 - loss: 0.4986 - val_accuracy: 0.7825 - val_loss: 0.4685\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9610 - loss: 0.1211 - val_accuracy: 0.7837 - val_loss: 0.5219\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9966 - loss: 0.0281 - val_accuracy: 0.7550 - val_loss: 0.6506\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9994 - loss: 0.0082 - val_accuracy: 0.7937 - val_loss: 0.7450\n"
          ]
        }
      ],
      "source": [
        "### Begin your code here\n",
        "# Train the model with two epochs, and a batch size of 100.\n",
        "# Tip: The x is X_train, y is y_train, and validation_data is (X_val, y_val)\n",
        "# To view the model.fit function definition check here: https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n",
        "# and also an example here: https://www.tensorflow.org/guide/keras/training_with_built_in_methods (Look for fit() )\n",
        "# To obtain a better accuracy you would need to train for more epochs. Find a right balance between the training time\n",
        "# and the accuracy\n",
        "# The parameters that you need to set are:\n",
        "# x as X_train\n",
        "# y as y_train\n",
        "# validation_data with the (X_val, y_val)\n",
        "# Choose and appropriate batch_size. You can experiment with different values and see how the model behaves.\n",
        "# When you first start training, only train for 1-2 epoch\n",
        "# Train the model with two epochs and a batch size of 100\n",
        "\n",
        "# Paramters for model1\n",
        "batch_size_model1 = 32\n",
        "epochs_model1 = 4\n",
        "\n",
        "history1 = model1.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=batch_size_model1,\n",
        "    epochs=epochs_model1,\n",
        ")\n",
        "\n",
        "# Parameters for model2\n",
        "batch_size_model2 = 32\n",
        "epochs_model2 = 8\n",
        "\n",
        "# Train model2 (Stacked LSTM)\n",
        "history2 = model2.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=batch_size_model2,\n",
        "    epochs=epochs_model2,\n",
        ")\n",
        "\n",
        "# Parameters for model3\n",
        "batch_size_model3 = 16\n",
        "epochs_model3 = 5\n",
        "\n",
        "# Train model3 (Bidirectional GRU)\n",
        "history3 = model3.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=batch_size_model3,\n",
        "    epochs=epochs_model3,\n",
        ")\n",
        "\n",
        "\n",
        "### End your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "WHc-p2qieW2l",
        "outputId": "b4f4a4b5-188a-45dc-884d-2e664e727ab6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Extract the loss values for each epoch and display it in a figure\n",
        "# BEGIN YOUR CODE HERE\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Extract loss values for training and validation from the history object\n",
        "train_loss = history1.history['loss']\n",
        "val_loss = history1.history['val_loss']\n",
        "\n",
        "# Create an array, epochs, containing integers from 1 to the number of epochs (inclusive)\n",
        "epochs = np.arange(1, len(train_loss) + 1)\n",
        "\n",
        "# Plot training and validation loss over epochs\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_loss, label='Training Loss', marker='o')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss', marker='o')\n",
        "\n",
        "# Add labels, title, grid, and legend\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# END YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNqB9Ufej6eG",
        "outputId": "cf9d3a49-4fa3-4416-c7e1-3ae78361edcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 117ms/step - accuracy: 0.7823 - loss: 0.7834\n",
            "Model 1 (Basic LSTM) - Test Loss: 0.6650\n",
            "Model 1 (Basic LSTM) - Test Accuracy: 0.8150\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8037 - loss: 0.6553\n",
            "Model 2 (Stacked LSTM) - Test Loss: 0.8775\n",
            "Model 2 (Stacked LSTM) - Test Accuracy: 0.6410\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7623 - loss: 0.8360\n",
            "Model 3 (Bidirectional GRU) - Test Loss: 0.8091\n",
            "Model 3 (Bidirectional GRU) - Test Accuracy: 0.7730\n",
            "\n",
            "Summary of Model Evaluation:\n",
            "Model 1 - Test Accuracy: 0.8150, Test Loss: 0.6650\n",
            "Model 2 - Test Accuracy: 0.6410, Test Loss: 0.8775\n",
            "Model 3 - Test Accuracy: 0.7730, Test Loss: 0.8091\n"
          ]
        }
      ],
      "source": [
        "# BEGIN YOUR CODE HERE\n",
        "# What is the loss and accuracy on the Testing dataset?\n",
        "# Tip: instead of (x_test, y_test) we used in the lab last week, you can use\n",
        "# directly test_ds which contains both data and labels\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate\n",
        "# When you print the output of the evaluate function, it will return both\n",
        "# the loss and accuracy, maybe in a  format like [loss_value, accuracy_value]\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#Add/remove to_numpy to reshape object if error appears when running\n",
        "y_test =y_test.to_numpy().reshape(-1, 1)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_pad_test, y_test)).batch(32)\n",
        "\n",
        "def evaluate_model(model, test_dataset, model_name):\n",
        "\n",
        "    test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "    print(f\"{model_name} - Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"{model_name} - Test Accuracy: {test_accuracy:.4f}\")\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "# (Basic LSTM)\n",
        "test_loss1, test_accuracy1 = evaluate_model(model1, test_ds, \"Model 1 (Basic LSTM)\")\n",
        "\n",
        "# (Stacked LSTM)\n",
        "test_loss2, test_accuracy2 = evaluate_model(model2, test_ds, \"Model 2 (Stacked LSTM)\")\n",
        "\n",
        "# (Bidirectional GRU)\n",
        "test_loss3, test_accuracy3 = evaluate_model(model3, test_ds, \"Model 3 (Bidirectional GRU)\")\n",
        "\n",
        "print(\"\\nSummary of Model Evaluation:\")\n",
        "print(f\"Model 1 - Test Accuracy: {test_accuracy1:.4f}, Test Loss: {test_loss1:.4f}\")\n",
        "print(f\"Model 2 - Test Accuracy: {test_accuracy2:.4f}, Test Loss: {test_loss2:.4f}\")\n",
        "print(f\"Model 3 - Test Accuracy: {test_accuracy3:.4f}, Test Loss: {test_loss3:.4f}\")\n",
        "\n",
        "### End your code here\n",
        "\n",
        "# What is the accuracy you get?\n",
        "# If you get an accuracy of aprox 50%, what does it mean? Did your model learn?\n",
        "# Try to modify the architecture; how you train the model or how much data you\n",
        "# use to train it in order to improve the results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnpIBL-kO6Hp"
      },
      "source": [
        "Test the model with a random text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSS9eiaLO9Y7",
        "outputId": "d8253806-6d79-4d10-e738-c218bea6e110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing...   8001/     3\rProcessing...   8002/     3\rProcessing...   8003/     3\r[['petter', 'mattei', 'love', 'time', 'money', 'visually', 'stun', 'film', 'watch', 'mr', 'mattei', 'offer', 'u', 'vivid', 'portrait', 'human', 'nature', 'movie', 'seem', 'tell', 'u', 'money', 'power', 'success', 'people'], ['movie', 'wa', 'terrible', 'plot', 'wa', 'predictable', 'act', 'wa', 'stiff', 'wait', 'end', 'waste', 'time'], ['incredible', 'cinematic', 'experience', 'storytelling', 'wa', 'brilliant', 'visuals', 'breathtaking', 'one', 'best', 'film', 'see', 'year']]\n",
            "Vectorizing sentences... (done)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 727ms/step\n",
            "Predicted positive with a probability of 0.9985 for review: Petter Mattei's 'Love in the Time of Money' is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human nature. This is a movie that seems to be telling us what money, power and success do to people.\n",
            "Predicted negative with a probability of 0.0135 for review: The movie was terrible. The plot was predictable, the acting was stiff, and I couldn't wait for it to end. A waste of time.\n",
            "Predicted positive with a probability of 0.9993 for review: An incredible cinematic experience. The storytelling was brilliant, and the visuals were breathtaking. One of the best films I've seen in years.\n"
          ]
        }
      ],
      "source": [
        "test_samples = []\n",
        "\n",
        "# Define a few sample reviews\n",
        "review1 = \"Petter Mattei's 'Love in the Time of Money' is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human nature. This is a movie that seems to be telling us what money, power and success do to people.\"\n",
        "review2 = \"The movie was terrible. The plot was predictable, the acting was stiff, and I couldn't wait for it to end. A waste of time.\"\n",
        "review3 = \"An incredible cinematic experience. The storytelling was brilliant, and the visuals were breathtaking. One of the best films I've seen in years.\"\n",
        "\n",
        "# Append the reviews to the test_samples list\n",
        "test_samples.append(review1)\n",
        "test_samples.append(review2)\n",
        "test_samples.append(review3)\n",
        "\n",
        "# Preprocess the reviews\n",
        "test_samples_preprocess = list(map(lambda x: preprocess(x, len(test_samples)), test_samples))\n",
        "print(test_samples_preprocess)\n",
        "\n",
        "# Convert to bigrams and trigrams\n",
        "test_data_bigrams = trigrams[bigrams[test_samples_preprocess]]\n",
        "\n",
        "# Vectorize the reviews using the trained model's vocabulary\n",
        "test_data_pad = pad_sequences(\n",
        "    sequences=vectorize_data(test_data_bigrams, vocab=trigram_model.wv.key_to_index),\n",
        "    maxlen=input_length,\n",
        "    padding='post'\n",
        ")\n",
        "\n",
        "# Get predictions for the reviews\n",
        "predictions = model1.predict(test_data_pad)\n",
        "\n",
        "# Print out the predicted sentiment for each review\n",
        "for (t, p) in zip(test_samples, predictions):\n",
        "    prediction_string = \"positive\"\n",
        "    if p < 0.5:\n",
        "        prediction_string = \"negative\"\n",
        "    print(f\"Predicted {prediction_string} with a probability of {p[0]:.4f} for review: {t}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "VRxTbMIXKaza"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}